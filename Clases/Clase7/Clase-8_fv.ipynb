{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "# <center>Clase 8, julio 7 del 2021 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "# <center> Topic that the Machine will learn: Handwritten Digit Recognition </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "From Learning Machines to Smart Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 >\n",
    "    \n",
    "[Smart machines:](./Literatura/What-is-smart-machines.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Classification Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "Classification predictive modeling is the task of approximating a mapping function F from input variables (X) to <font color='red' > $\\bf discrete$ <font color='black' > target variables (Y). In statistics a variable that can take on one of a limited number of possible values is called a $\\bf categorical$ $\\bf variable$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Regression Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "Regression predictive modeling is the task of approximating a mapping function F from input variables (X) to a <font color='red' > $\\bf continuous$ <font color='black' > target variable (Y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "A classification problem requires that samples be classified into one of two or more classes.\n",
    "\n",
    "A classification can have real-valued or discrete input variables.\n",
    "\n",
    "A problem with two classes is often called a two-class or binary classification.\n",
    "\n",
    "A problem with more than two classes is often called a multi-class classification.\n",
    "\n",
    "A problem where a sample is assigned multiple classes is called a multi-label classification.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T17:16:20.479536Z",
     "start_time": "2020-11-16T17:16:20.470759Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Information about the topic: Handwritten Digit Recognition using MNIST database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "[Hand written Zip code recognition](./Literatura/Back-propag-hand-written-cnn-lecun-1989.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits (samples) that is commonly used for training various image processing systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:05.966969Z",
     "start_time": "2020-11-17T21:24:04.476726Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import pydot\n",
    "import IPython\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "np.random.seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numpy version\", np.__version__)\n",
    "print(\"TensorFlow version\", tf.__version__)\n",
    "print(\"Keras version\", keras.__version__)\n",
    "print(\"Pydot version\", pydot.__version__)\n",
    "print(\"Ipython version\", IPython.__version__)\n",
    "print(\"Matplotlib version\", matplotlib.__version__)\n",
    "print(\"Pickle version\", pickle.format_version)\n",
    "from platform import python_version\n",
    "print(\"Python version\", python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T17:41:15.942872Z",
     "start_time": "2020-11-16T17:41:15.933507Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Samples preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <font size=4 color='black'>   \n",
    "The database mnist of samples can be downloaded from the following URL: \n",
    "    \n",
    "[MNIST data download](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The samples to train and test the neuronal network are in the file 'mnist.pkl.gz'.\n",
    "\n",
    "    gzip.open(filename, mode='rb') open the compressed binary file 'filename'.\n",
    "    \n",
    "   The documentation of gzip.open can be found at [gzip.open(...)](https://docs.python.org/3/library/gzip.html#gzip.open)\n",
    "\n",
    "    pickle.load(file, encoding = 'latin1') decode the file 'file' in latin1\n",
    "\n",
    "Documentation: [pickle.load(...)](https://docs.python.org/3/library/pickle.html#pickle.load)\n",
    "\n",
    "The function 'load_samples()' has three samples sets as output: \n",
    "\n",
    "    learn_samples  # Samples for training\n",
    "    val_samples    # Samples for validation\n",
    "    test_samples   # Samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:05.972096Z",
     "start_time": "2020-11-17T21:24:05.968383Z"
    }
   },
   "outputs": [],
   "source": [
    "# The database is in the working directory: mnist.pkl.gz file.\n",
    "    \n",
    "def load_samples():\n",
    "\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    \n",
    "    learn_samples, val_samples, test_samples = pickle.load(f, encoding=\"latin1\")\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return (learn_samples, val_samples, test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.792093Z",
     "start_time": "2020-11-17T21:24:05.974070Z"
    }
   },
   "outputs": [],
   "source": [
    "# the samples are loaded in three sets: train_samples, val_samples and test_samples \n",
    "\n",
    "learn_samples, val_samples, test_samples = load_samples()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "Each of these sets is a tuple with two entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.798287Z",
     "start_time": "2020-11-17T21:24:06.793584Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The type of train_samples: \", type(learn_samples), \"with length: \", len(learn_samples) )\n",
    "print(\"The type of val_data: \", type(val_samples), \"with length: \", len(val_samples) )\n",
    "print(\"The type of test_data: \", type(test_samples), \"with length: \", len(test_samples) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.810520Z",
     "start_time": "2020-11-17T21:24:06.799891Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Shape of the first element of the train_data tuple: \", learn_samples[0].shape)\n",
    "print(\"Shape of the second element of the train_data tuple: \", learn_samples[1].shape)\n",
    "print(\"Shape of the first element of the val_data tuple: \", val_samples[0].shape)\n",
    "print(\"Shape of the second element of the val_data tuple: \", val_samples[1].shape)\n",
    "print(\"Shape of the first element of the test_data tuple: \", test_samples[0].shape)\n",
    "print(\"Shape of the second element of the test_data tuple: \", test_samples[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T16:53:44.374743Z",
     "start_time": "2020-03-24T16:53:44.366238Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Analyzing the samples extracted from MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The first entry of a sample corresponds to the network input, the values of the pixels, which are the image features. The second entry corresponds to the target variable. It is the digit value associated to the image. $$$$It is to note that pixel values were rescaled to values between 0.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.822702Z",
     "start_time": "2020-11-17T21:24:06.811843Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"features 150 to 199 of the first training sample \\n \\n\", learn_samples[0][0][150:200])\n",
    "print(\"\\n y value of the first training sample =\",learn_samples[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:18:56.606700Z",
     "start_time": "2020-03-24T20:18:56.598151Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "Viewing one sample from the data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "The digits in the MNIST dataset are images of 28x28 pixels. \n",
    "    \n",
    "In the recovered datasets, images were represented by vectors of dimension 28x28=784. \n",
    "    \n",
    "To deploy the digit image of a sample (index), its vector representation is changed to a matrix with dimensions 28x28.\n",
    "    \n",
    "    \n",
    "This is done by using the following function:\n",
    "    \n",
    "plt.imshow(sets[0][index].reshape((28, 28)),cmap='gray')      #Images are in shades of gray\n",
    "\n",
    "Documentation: [matplotlib.pyplot.imshow(...)](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.960465Z",
     "start_time": "2020-11-17T21:24:06.823984Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "plt.imshow(learn_samples[0][index].reshape((28, 28)),cmap='gray')\n",
    "\n",
    "print(learn_samples[1][index], \"is the digit corresponding to the sample\", index)\n",
    "print(\"\\n This is its image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Separation of the samples into features (inputs) and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.965967Z",
     "start_time": "2020-11-17T21:24:06.962735Z"
    }
   },
   "outputs": [],
   "source": [
    "x_learn = learn_samples[0]   # input (features) in the training data set\n",
    "y_learn = learn_samples[1]   # target (the digit) in the training data set\n",
    "\n",
    "x_val = val_samples[0]   # input (features) in the validation data set\n",
    "y_val = val_samples[1]   # target (the digit) in the validation data set\n",
    "\n",
    "x_test = test_samples[0]     # input (features) in the testing data set\n",
    "y_test = test_samples[1]     # target (the digit) in the testing data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.979375Z",
     "start_time": "2020-11-17T21:24:06.968001Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(x_learn))\n",
    "print(x_learn.shape)\n",
    "print(y_learn.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:06.991634Z",
     "start_time": "2020-11-17T21:24:06.980745Z"
    }
   },
   "outputs": [],
   "source": [
    "y_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "One-hot encoding of the target variable Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The target value can have one of ten elements (classes), the digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9). \n",
    "\n",
    "The train_y and test_y sets are arrangements in which each entry contains a digit. Each digit is represented as a integer of 64 bits.\n",
    "    \n",
    "We change this representation to a vectorial one following One-hot encoding \n",
    "[One-hot encoding](https://en.wikipedia.org/wiki/One-hot).\n",
    "    \n",
    "In the One-Hot encoding, a digit is represented with a vector having dimension 10 (because we have 10 classes) with 1.0 in the vector index corresponding to the digit and 0.0 elsewhere in the vector. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue' >\n",
    "    \n",
    "Digit |     One-hot representation \n",
    "--- | --- \n",
    " 0  | [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " 1  | [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " 2  | [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " 3  | [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    " 4  | [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    " 5  | [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    " 6  | [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " 7  | [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " 8  | [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    " 9  | [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='purple'>\n",
    "Demo using numpy.eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.004858Z",
     "start_time": "2020-11-17T21:24:06.992874Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.016302Z",
     "start_time": "2020-11-17T21:24:07.006472Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.028455Z",
     "start_time": "2020-11-17T21:24:07.017626Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.040513Z",
     "start_time": "2020-11-17T21:24:07.029624Z"
    }
   },
   "outputs": [],
   "source": [
    "y_learn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T19:22:13.283991Z",
     "start_time": "2020-11-16T19:22:13.273520Z"
    }
   },
   "source": [
    "np.eye(10)[train_y[0:5].reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.054673Z",
     "start_time": "2020-11-17T21:24:07.041917Z"
    }
   },
   "outputs": [],
   "source": [
    "np.eye(10)[y_learn[0:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='purple'>\n",
    "End of demo using numpy.eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.068451Z",
     "start_time": "2020-11-17T21:24:07.056597Z"
    }
   },
   "outputs": [],
   "source": [
    "learn_y = np.eye(10)[y_learn]\n",
    "\n",
    "val_y = np.eye(10)[y_val]\n",
    "\n",
    "test_y = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.078264Z",
     "start_time": "2020-11-17T21:24:07.070283Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Y: Digit representation for the first learning sample \\n\", y_learn[0])\n",
    "print(\"Y: One-hot representation for the first leaning sample \\n\",learn_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "For convenience, the dimensions of the input sets will be changed to the format:\n",
    "\n",
    "(number of samples, image width, image length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.090004Z",
     "start_time": "2020-11-17T21:24:07.079918Z"
    }
   },
   "outputs": [],
   "source": [
    "learn_x = x_learn.reshape(50000, 28, 28)\n",
    "val_x  = x_val.reshape(10000, 28, 28)\n",
    "test_x = x_test.reshape(10000, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "In summary, the learning and test sample sets are based on the following dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.103786Z",
     "start_time": "2020-11-17T21:24:07.091277Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"number of learning samples = \" + str(learn_x.shape[0]))\n",
    "print (\"number of validation samples = \" + str(val_x.shape[0]))\n",
    "print (\"number of test samples = \" + str(test_x.shape[0]))\n",
    "print (\"learn_x shape: \" + str(learn_x.shape))\n",
    "print (\"learn_y shape: \" + str(learn_y.shape))\n",
    "\n",
    "print (\"val_x shape: \" + str(val_x.shape))\n",
    "print (\"val_y shape: \" + str(val_y.shape))\n",
    "\n",
    "print (\"test_x shape: \" + str(test_x.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:05:44.199775Z",
     "start_time": "2020-03-24T17:05:44.190483Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Constructing the Learning Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Model of the Machine: Full-Connected Feed-Forward Network (FF) with one hidden layer with twenty neurons. The nodes in the output layer will be activated with the softmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T17:05:44.199775Z",
     "start_time": "2020-03-24T17:05:44.190483Z"
    }
   },
   "source": [
    "<font size=5 color=\"black\">\n",
    "\n",
    "\n",
    "The architecture of the neural network will be shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.249974Z",
     "start_time": "2020-11-17T21:24:07.105436Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "class Network(object):\n",
    "    \n",
    "    def  __init__ (self,sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        print(\"It has\", self.num_layers, \"layers,\")\n",
    "        self.sizes = sizes\n",
    "        print(\"with the following number of nodes per layer\",self.sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self, x_of_sample):\n",
    "        \"\"\"Return the output of the network F(x_of_sample) \"\"\"        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            x_of_sample = sigmoid(np.dot(w, x_of_sample)+b)\n",
    "        return x_of_sample\n",
    "    \n",
    "    def graph(self,sizes):\n",
    "        a=[]\n",
    "        ps={}\n",
    "        Q = nx.Graph()\n",
    "        for i in range(len(sizes)):\n",
    "            Qi=nx.Graph()    \n",
    "            n=sizes[i]\n",
    "            nodos=np.arange(n)\n",
    "            Qi.add_nodes_from(nodos)\n",
    "            l_i=Qi.nodes\n",
    "            Q = nx.union(Q, Qi, rename = (None, 'Q%i-'%i))\n",
    "            if len(l_i)==1:\n",
    "                ps['Q%i-0'%i]=[i/(len(sizes)), 1/2]\n",
    "            else:\n",
    "                for j in range(len(l_i)+1):\n",
    "                    ps['Q%i-%i'%(i,j)]=[i/(len(sizes)),(1/(len(l_i)*len(l_i)))+(j/(len(l_i)))]\n",
    "            a.insert(i,Qi)\n",
    "        for i in range(len(a)-1):\n",
    "            for j in range(len(a[i])):\n",
    "                for k in range(len(a[i+1])):\n",
    "                    Q.add_edge('Q%i-%i' %(i,j),'Q%i-%i' %(i+1,k))\n",
    "        nx.draw(Q, pos = ps)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.844313Z",
     "start_time": "2020-11-17T21:24:07.251233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Architecture of the neural network we want to implement in the present notebook\n",
    "\n",
    "layers = [784,20,10]\n",
    "net = Network(layers)\n",
    "net.graph(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Definition of the neural network architecture\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='black'> \n",
    "    \n",
    "Keras has two different modes to define the architecture:\n",
    "\n",
    "<font size=4 color='black'> \n",
    "    \n",
    "1.- The sequential model. It is a sequential stack of layers.\n",
    "    \n",
    "2.- The functional API. It is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers.  \n",
    "\n",
    "In the present case, we will use this last mode for constructing the architecture of the network.\n",
    "    \n",
    "\n",
    "Documentation: [Keras Functional API](https://keras.io/getting-started/functional-api-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.852568Z",
     "start_time": "2020-11-17T21:24:07.845843Z"
    }
   },
   "outputs": [],
   "source": [
    "def architecture(input_shape, num_clases):\n",
    "    \n",
    "    # Defining the input as a tensor with shape input_shape. \n",
    "    inputs = Input(input_shape, name='input-layer')\n",
    "    \n",
    "    # Flattening the input tensor of dimensions (28,28,1) to a tensor of dimensions (784, 1)\n",
    "    x = Flatten()(inputs)\n",
    "    \n",
    "    # Defining the first hidden layer with 20 nodes and sigmoid as activation function\n",
    "    x = Dense(20, kernel_initializer='uniform', bias_initializer='zeros', name='hidden-layer')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    # Defining the output layer with num_clases nodes \n",
    "    x = Dense(num_clases, kernel_initializer='uniform', bias_initializer='zeros')(x)\n",
    "    \n",
    "    # For the output layer we use the activation function 'softmax'\n",
    "    outputs = Activation('softmax', name='output.layer')(x)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.    \n",
    "    arch_model = Model(inputs = inputs, outputs = outputs, name='MnistModel')\n",
    "\n",
    "    return arch_model"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'> \n",
    "\n",
    "    \n",
    "   *The softmax activation function is always used for classification when the number (K) of classes is larger than two.* \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "    \n",
    "[Activation functions](./Literatura/activation_functions_2018.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T18:29:47.071906Z",
     "start_time": "2020-03-24T18:29:47.067719Z"
    }
   },
   "source": [
    "\n",
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Constructing the neural network model for the Learning Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:07.919154Z",
     "start_time": "2020-11-17T21:24:07.856354Z"
    }
   },
   "outputs": [],
   "source": [
    "one_image = (28,28)\n",
    "num_classes= 10\n",
    "\n",
    "# Generating a model using the architecture defined for the neural network\n",
    "mnist_model = architecture(one_image, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:03:50.539765Z",
     "start_time": "2020-03-24T00:03:50.534266Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "Model plot and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'> \n",
    "The function 'plot_model()' generates a graphic with the layers and their number of input ands output weights.\n",
    "$$ $$\n",
    "Documentation: [Model visualization](https://keras.io/visualization/#training-history-visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.012027Z",
     "start_time": "2020-11-17T21:24:07.920779Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(mnist_model, to_file='FF_mnist_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.018904Z",
     "start_time": "2020-11-17T21:24:08.013470Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T22:54:01.482701Z",
     "start_time": "2020-11-15T22:54:01.471240Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "This requires defining the optimization algorithm, the loss function and the metric.\n",
    "    \n",
    "In the present case we are using the algorithm of Stochastic Gradient descent with learning rate \"lr\", \"momentum\" without Nesterov acceleration\".\n",
    "\n",
    "\n",
    "[An overview of gradient descent optimization algorithms](./Literatura/SGD_overview_2016-17.pdf)\n",
    "\n",
    "This publication also comments some other optimization variants of this algorithm; Adagrad, Adadelta, RMStrop and Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T18:24:57.726929Z",
     "start_time": "2020-11-17T18:24:57.717602Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.045698Z",
     "start_time": "2020-11-17T21:24:08.020323Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T18:09:46.075549Z",
     "start_time": "2020-11-17T18:09:46.071063Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "The cost (loss) and Metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "The cost function *J* is the one defined as \"categorical_crossentropy\"\n",
    "    \n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=0}^{K-1}(y_k^{(i)}*\\log{(F_k(x^{(i)})))}$$\n",
    "    \n",
    " where $F_k(x^{(i)})$ is the predicted value and $y_k^{(i)}$ is the target value for the sample *i*; *K* is the number of classes and *m* is the number of samples.\n",
    "    \n",
    "[Cross entropy](https://en.wikipedia.org/wiki/Cross_entropy)\n",
    "    \n",
    "[Categorical cross entropy](https://www.deeplearningbook.org/)\n",
    "    \n",
    "\n",
    "A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model. You may use any of the loss functions as a metric function. In the present example, we are using \"accuracy\" as metrics:\n",
    "    \n",
    "*Accuracy = Number of correct predictions / Total number of predictions made*\n",
    "    \n",
    "\n",
    "Categorical crossentropy will compare the distribution of the predictions (the activations in the output layer, one for each class) with the true distribution, where the probability of the true class is set to 1, and 0 for the other classes.\n",
    "\n",
    "To put it in a different way, the true class is represented as an encoded vector, and the closer the model’s outputs are to that vector, the lower the loss.\n",
    "    \n",
    "Documentation: [keras.compile(...)](https://keras.io/models/model/#compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.049657Z",
     "start_time": "2020-11-17T21:24:08.047124Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = 'categorical_crossentropy'\n",
    "metric_function = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:24:08.108610Z",
     "start_time": "2020-11-17T21:24:08.051598Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_model.compile(optimizer = optimizer, loss = loss_function, metrics = [metric_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "The Machine is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "Documentation: [keras.fit(...)](https://keras.io/models/model/#fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:30.676613Z",
     "start_time": "2020-11-17T21:24:08.110028Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "history = mnist_model.fit(x = learn_x, y = learn_y, epochs=num_epochs, batch_size = 100, \\\n",
    "                          validation_data=(val_x,val_y), shuffle=False, verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time for learning: {:10.4f}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "* Note: if you run `fit()` again, the `model` will continue learning, starting with the parameters it has already learnt, instead of reinitializing them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Plotting the cost function of the learning and validation data sets as a function of the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:30.833216Z",
     "start_time": "2020-11-17T21:25:30.678097Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Cost function', size=16)\n",
    "plt.ylabel('Cost', size=16)\n",
    "plt.xlabel('Epoch', size=16)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right', prop={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "Plotting the accuracy function of the learning and validation sets as a function of the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:30.956998Z",
     "start_time": "2020-11-17T21:25:30.834617Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy', size=16)\n",
    "plt.ylabel('Accuracy', size=16)\n",
    "plt.xlabel('Epoch', size=16)\n",
    "plt.legend(['Train', 'Validation'], loc='lower right', prop={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='blue'>\n",
    "\n",
    "Loss and accuracy evaluation using the Smart Machine and the test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= 4 color='black'>    \n",
    "After the network learnt, the loss and accuracy functions are evaluated using the test samples (test_x, test_y). This is done using the Keras Method evaluate(x=None, y=None, ...).\n",
    "    \n",
    "\n",
    "    \n",
    "[Method evaluate in Keras](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.307565Z",
     "start_time": "2020-11-17T21:25:30.959211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation using all the samples of the test set\n",
    "evaluations = mnist_model.evaluate(x = test_x, y = test_y)\n",
    "\n",
    "print (\"Loss = \" + str(evaluations[0]))\n",
    "print (\"Test Accuracy = \" + str(evaluations[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.318940Z",
     "start_time": "2020-11-17T21:25:31.308874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation using the first 100 samples of the test set\n",
    "\n",
    "evaluations = mnist_model.evaluate(x = test_x[:100], y = test_y[:100])\n",
    "\n",
    "print (\"Loss = \" + str(evaluations[0]))\n",
    "print (\"Test Accuracy = \" + str(evaluations[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='blue'>\n",
    "Digits prediction with the Smart Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= 4 color='black'>    \n",
    "The smart machine generates predictions of the digists associated to new samples. For example, those in the test data (test_x, test_y). This is done using the Keras Method \"predict(x, ...)\"\n",
    "      \n",
    "[Method predict in Keras](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.525053Z",
     "start_time": "2020-11-17T21:25:31.320209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting the digits associated to each sample in the test set (test_x)\n",
    "predictions = mnist_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.529800Z",
     "start_time": "2020-11-17T21:25:31.526287Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = 34\n",
    "\n",
    "# Predicting the digit associated to the sample \n",
    "# np.argmax returns the index of the maximum value\n",
    "\n",
    "prediction = np.argmax(predictions[sample])\n",
    "\n",
    "print('For the sample number', sample, 'the prediction is the digit:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\"> \n",
    "Displaying the digit associated (not predicted!) to this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:31.638216Z",
     "start_time": "2020-11-17T21:25:31.531127Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_samples[0][sample].reshape((28, 28)), cmap='gray')\n",
    "\n",
    "print ('For the sample number', sample, 'the associated digit is:', np.squeeze(test_samples[1][sample]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='blue'>\n",
    "Reseting all state generated by Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 >\n",
    "Keras manages a global state, which it uses to implement the Functional model-building API and to uniquify autogenerated layer names.  \n",
    "If you are creating many models in a loop, this global state will consume an increasing amount of memory over time, and you may want to clear it. Calling clear_session() releases the global state: this helps avoid clutter from old models and layers, especially when memory is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
