{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T01:21:08.810200Z",
     "start_time": "2020-03-04T01:21:08.804251Z"
    }
   },
   "source": [
    "<font size=6 color='blue'>\n",
    "\n",
    "<center> Clase 5, junio 23 del 2021 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T23:31:40.881412Z",
     "start_time": "2020-10-11T23:31:40.873889Z"
    }
   },
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "## Tópico de estudio: Mortalidad por diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "## Información sobre el tópico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Evolución de la enfermedad de pacientes con Diabetes Mellitus despues de un año.\n",
    "    \n",
    "En el presente trabajo, la diabetes la caracterizamos con los siguientes diez rasgos: edad, sexo, índice de masa corporal, presión arterial promedio y seis mediciones de suero sanguíneo:\n",
    "\n",
    "     Colesterol Total \n",
    "     Baja densidad de liporoteinas\n",
    "     Alta densidad de lipoproteinas\n",
    "     Triglicéridos\n",
    "     Concentración de Lamorigina\n",
    "     Glucosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Cuantificación de esta información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Se tienen información de 442 pacientes (m = 442). La respuesta de interés, Y, es una medida cuantitativa de la progresión de la enfermedad un año después del inicio del estudio. Los valores de Y varían entre 25 y 346\n",
    "\n",
    "Fuente de la información: [diabetes data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)    Artículo original: [Least-Angle-Regression_2004](./Literatura/Least-Angle-Regression_2004.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:23.916483Z",
     "start_time": "2020-10-19T12:30:23.496513Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:23.924252Z",
     "start_time": "2020-10-19T12:30:23.918002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Los datos se encuentran el el archivo diabetes.csv\n",
    "\n",
    "df = pd.read_csv('diabetes.csv', sep ='\\t')\n",
    "\n",
    "# se crea el dataframe df, el cual contiene los 10 rasgos relevantes de los pacientes\n",
    "# diabeticos, así como el progreso (y) de la enfermedad un año después de comenzado el estudio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:23.944167Z",
     "start_time": "2020-10-19T12:30:23.926085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se despliegan las primeras 5 muestras (rasgos, objetivo)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Las abreviaciones tienen el siguiente significado:\n",
    "    \n",
    "    AGE = Age\n",
    "    SEX = Sex\n",
    "    BMI = Body Mass Index (BMI)\n",
    "     BP = Mean Arterial Pressure (MAP)\n",
    "     S1 = Total Cholesterol (TC)\n",
    "     S2 = Low Density lipoproteins (LDL)\n",
    "     S3 = High Density lipoproteins (HDL)\n",
    "     S4 = Triglyceride (TG, TCH)\n",
    "     S5 = Serum Concentration of Lamorigine (LTG)\n",
    "     S6 = Glucose (GLU)\n",
    "     Y = Quantitative Measure of Diabetes Mellitus Disease Progression (QMDMDP) one year after the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:24.001227Z",
     "start_time": "2020-10-19T12:30:23.946501Z"
    }
   },
   "outputs": [],
   "source": [
    "# el método describe() genera una tabla con informacion estadistica de cada uno de los rasgos y del objetivo.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se crean los histogramas para cada uno de los rasgos que caracteriza a los pacientes con diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:24.547926Z",
     "start_time": "2020-10-19T12:30:24.003081Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df.AGE, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('Age (years)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.SEX, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('Sex', size=15)\n",
    "\n",
    "ax3.hist(df.BMI, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('Body_mass_index', size=15)\n",
    "\n",
    "ax4.hist(df.BP, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('Mean_Arterial_Pressure', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:25.072629Z",
     "start_time": "2020-10-19T12:30:24.549466Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df.S1, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('Total Cholesterol', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.S2, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('Low Density lipoproteins', size=15)\n",
    "\n",
    "ax3.hist(df.S3, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('High Density lipoproteins', size=15)\n",
    "\n",
    "ax4.hist(df.S4, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('Triglyceride', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:25.479025Z",
     "start_time": "2020-10-19T12:30:25.074767Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,3,1)\n",
    "ax2 = plt.subplot(2,3,2)\n",
    "ax3 = plt.subplot(2,3,3)\n",
    "\n",
    "ax1.hist(df.S5, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('Serum Concentration of Lamorigine', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.S6, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('Glucose', size=15)\n",
    "\n",
    "ax3.hist(df.Y, bins=30, color='purple',edgecolor='black', alpha=0.5)\n",
    "ax3.set_xlabel('Y(Diabetes Mellitus Disease Progression)', size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:21:23.071130Z",
     "start_time": "2020-10-13T20:21:23.062454Z"
    }
   },
   "source": [
    "<font size=4>\n",
    "\n",
    "Para quitar cualquier posible correlación entre las muestras (los renglones del DataFrame), estos se reordenan al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:25.486225Z",
     "start_time": "2020-10-19T12:30:25.482411Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "División de las muestras para aprender y para hacer predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Se dividen la muestras originales en 2 conjuntos: 90 % para el entrenamiento y 10 % para hacer inferencias (predicciones) con el sistema de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:25.500836Z",
     "start_time": "2020-10-19T12:30:25.488111Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.1\n",
    "\n",
    "train_ratio = int((1.0-test_ratio)*len(df.values[:,:]))\n",
    "\n",
    "df_train = df.iloc[0:train_ratio,:]\n",
    "df_test  = df.iloc[train_ratio:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:25.513777Z",
     "start_time": "2020-10-19T12:30:25.502520Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Para trabajar con los modelos de aprendizaje,es adecuado que todas las variables tengan el mismo orden de magnitud. Por ello, se normalizan sus valores en las muestras que se emplearán en el entrenamiento, tanto los rasgos (X) y las variables objetivo (Y):\n",
    "\n",
    "$$x_{i,norm} = \\dfrac{x_{i}-\\mu}{\\sigma}$$\n",
    "    \n",
    "$$y_{i,norm} = \\dfrac{y_{i}-\\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:25.535595Z",
     "start_time": "2020-10-19T12:30:25.515747Z"
    }
   },
   "outputs": [],
   "source": [
    "mu = df_train.mean()\n",
    "sigma = df_train.std()\n",
    "df_train_norm = (df_train - mu)/ sigma\n",
    "df_train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'> \n",
    "Nota importante: La normalización de las muestras de prueba se realiza con los valores de $\\mu$ y $\\sigma$ obtenidos con las muestras empleadas para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:25.549131Z",
     "start_time": "2020-10-19T12:30:25.536981Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_norm = (df_test - mu) / sigma\n",
    "df_test_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Histogramas de las variables que se emplearán en el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:26.033391Z",
     "start_time": "2020-10-19T12:30:25.550355Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df_train_norm.AGE, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x1(Age)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.SEX, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x2(Sex)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.BMI, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('x3(Body_mass_index)', size=15)\n",
    "\n",
    "ax4.hist(df_train_norm.BP, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('x4(Mean_Arterial_Pressure)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:26.558573Z",
     "start_time": "2020-10-19T12:30:26.034940Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df_train_norm.S1, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x5(Total Cholesterol)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.S2, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x6(Low Density lipoproteins)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.S3, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('x7(High Density lipoproteins)', size=15)\n",
    "\n",
    "ax4.hist(df_train_norm.S4, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('x8(Triglyceride)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:26.960464Z",
     "start_time": "2020-10-19T12:30:26.560100Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,3,1)\n",
    "ax2 = plt.subplot(2,3,2)\n",
    "ax3 = plt.subplot(2,3,3)\n",
    "\n",
    "ax1.hist(df_train_norm.S5, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x9(Serum Concentration of Lamorigine)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.S6, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x10(Glucose)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.Y, bins=30, color='purple',edgecolor='black', alpha=0.5)\n",
    "ax3.set_xlabel('Y(Diabetes Mellitus Disease Progression)', size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Los valores de las variables X e Y se extraen de las columnas del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:26.964985Z",
     "start_time": "2020-10-19T12:30:26.961850Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = df_train_norm.values[:,:-1]\n",
    "train_y = df_train_norm.values[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:26.977641Z",
     "start_time": "2020-10-19T12:30:26.966303Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x = df_test_norm.values[:,:-1]\n",
    "test_y = df_test_norm.values[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:26.991865Z",
     "start_time": "2020-10-19T12:30:26.979131Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_x.T\n",
    "x_test = test_x.T\n",
    "\n",
    "y_train = train_y.T\n",
    "y_test = test_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.007099Z",
     "start_time": "2020-10-19T12:30:26.993169Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.021962Z",
     "start_time": "2020-10-19T12:30:27.008344Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "# <center> Artificial Neural Networks </center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T00:30:05.725975Z",
     "start_time": "2020-10-18T00:30:05.722770Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Implementada con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Inspirandose en modelos que intentan describir las conecciones entre las neuronas en nuestro cerebro, se propusieron (y se siguen proponiendo) modelos de redes neuronales para generar sistemas de aprendizaje. Se les conoce con el nombre de redes neuronales artificiales, o simplemente como redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Implementación de una red neuronal del tipo \"Full-Connected Feed-forward (FFF)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "<p>En nuestro primer modelo, la red neuronal tiene 3 capas: la capa de entrada, la capa de salida y una capa interior (en la literatura, a esta capa interna se le da el nombre de capa oculta). </p>\n",
    "<p>El objetivo del modelo es encontrar una función que describa la evolución de la Diabetes Mellitus en una año, a partir de su linea base, con los rasgos de la persona que se consideran importantes para su evolución. Los rasgos propuestos son: edad, sexo, índice de masa corporal, presión arterial promedio y las seis mediciones de suero sanguíneo descritas al inicio: el colesterol total, la densidad baja de lipoproteinas, la densidad alta de lipoproteinas, los trigliceridos, la concentración de lamorigina y la glucosa</p>\n",
    "<p>Esta función se genera mediante una red de neuronas artificiales. Se entiende como neurona un modelo matemático simple de una neurona biológica.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T17:48:13.294187Z",
     "start_time": "2020-10-14T17:48:13.290898Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Adecuando lo datos de alimentación al sistema de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Antes de inciar el desarrollo del sistema, transformamos los datos de entrada para que sean compatibles con el modelo que desarrollaremos. El fomato de entrada de las variables X y Y, tanto para el entrenamiento como para la prueba es un poco diferente al empleado en los sistemas de aprendizaje anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Definición de la arquitectura de la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:06:46.389123Z",
     "start_time": "2020-10-13T17:06:46.381702Z"
    }
   },
   "source": [
    "<font size=4>\n",
    "    \n",
    "Se emplea indistintamente la palabra neurona o nodo para referirse al modelo matematico de la neurona.\n",
    "\n",
    "El número de nodos en la capa de entrada depende del numero de rasgos del sistema que definen la variable objetivo, la evolución de la diabetes en un año. En el presente caso el número de rasgos es diez.\n",
    "\n",
    "El número de nodos en la capa de salida depende del tipo de problema. En el presente caso, se tiene una sola neurona, cuya salida nos da un número que cuantifica la evolución de la diabetes en un año.\n",
    "\n",
    "En el presente modelo, sólo tenemos una capa interna, el número de nodos en ella es variable. Se hacen pruebas con diferentes números y se adopta el que de los mejores resultados.\n",
    "\n",
    "La función layer_sizes() genera la arquitectura de la red neuronal partiendo de los datos con que se van a alimentar a la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.036758Z",
     "start_time": "2020-10-19T12:30:27.023466Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y, n_h):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input dataset of shape (input size, number of examples)\n",
    "    Y -- labels of shape (output size, number of examples)\n",
    "    \n",
    "    Return:\n",
    "    n_x -- the size of the input layer\n",
    "    n_h -- the size of the hidden layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    n_x = X.shape[0] \n",
    "    n_h = n_h\n",
    "    n_y = Y.shape[0]\n",
    "    \n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.049992Z",
     "start_time": "2020-10-19T12:30:27.038304Z"
    }
   },
   "outputs": [],
   "source": [
    "n_h = 4\n",
    "n_x, n_h, n_y = layer_sizes(x_train, y_train, n_h = n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.065177Z",
     "start_time": "2020-10-19T12:30:27.053659Z"
    }
   },
   "outputs": [],
   "source": [
    "print(n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Visualización de la red     \n",
    " \n",
    "<font size=4 color='black'> \n",
    "    \n",
    "Usaremos NetworkX, que es un paquete de Python para la creación, manipulación y estudio de la estructura, dinámica y funciones de redes complejas.\n",
    "    \n",
    "[NetworkX](https://networkx.github.io/)\n",
    "\n",
    "Lo pueden instalar usando:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ conda install -c anaconda networkx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.253736Z",
     "start_time": "2020-10-19T12:30:27.068319Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "class Network(object):\n",
    "    \n",
    "    def  __init__ (self,sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        print(\"It has\", self.num_layers, \"layers,\")\n",
    "        self.sizes = sizes\n",
    "        print(\"with the following number of nodes per layer\",self.sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self, x_of_sample):\n",
    "        \"\"\"Return the output of the network F(x_of_sample) \"\"\"        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            x_of_sample = sigmoid(np.dot(w, x_of_sample)+b)\n",
    "        return x_of_sample\n",
    "    \n",
    "    def graph(self,sizes):\n",
    "        a=[]\n",
    "        ps={}\n",
    "        Q = nx.Graph()\n",
    "        for i in range(len(sizes)):\n",
    "            Qi=nx.Graph()    \n",
    "            n=sizes[i]\n",
    "            nodos=np.arange(n)\n",
    "            Qi.add_nodes_from(nodos)\n",
    "            l_i=Qi.nodes\n",
    "            Q = nx.union(Q, Qi, rename = (None, 'Q%i-'%i))\n",
    "            if len(l_i)==1:\n",
    "                ps['Q%i-0'%i]=[i/(len(sizes)), 1/2]\n",
    "            else:\n",
    "                for j in range(len(l_i)+1):\n",
    "                    ps['Q%i-%i'%(i,j)]=[i/(len(sizes)),(1/(len(l_i)*len(l_i)))+(j/(len(l_i)))]\n",
    "            a.insert(i,Qi)\n",
    "        for i in range(len(a)-1):\n",
    "            for j in range(len(a[i])):\n",
    "                for k in range(len(a[i+1])):\n",
    "                    Q.add_edge('Q%i-%i' %(i,j),'Q%i-%i' %(i+1,k))\n",
    "        nx.draw(Q, pos = ps)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.323262Z",
     "start_time": "2020-10-19T12:30:27.255156Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = [n_x, n_h, n_y]\n",
    "net = Network(layers)\n",
    "net.graph(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Inicializacion de los pesos y los bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Debido a que las variables X y Y fueron normalizadas a distribuciones con un deviación estándard de 1, las variables $w$ se inicializan con valores pequeños, mientras que los biases se inicializan a cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "La funcion initialize_parameters() inicializa a los pesos $W$ y el bias $b$. \n",
    "\n",
    "Dado que se tiene un conjunto de variables independientes, se debe definir un peso para cada variable, esto para una sola neurona de la siguiente capa. \n",
    "\n",
    "Entonces $W_1$ ahora es una matriz de tamaño $(n_h, n_x)$, en donde $n_h$ es el numero de nodos en la capa intera y $n_x$ es el numero de nodos en la capa de entrada, es decir, es el numero de variables independientes (rasgos).\n",
    "\n",
    "Para cada neurona en la capa interna hay un bias, por lo que ahora $b_1$ es un vector de tamaño $(n_h, 1)$. \n",
    "\n",
    "En general para cada par de capas consecutivas debe haber un $W$ y un $b$.\n",
    "\n",
    "Generalizando:\n",
    "\n",
    "$W_i$ y $b_i$ son los parametros a definir entre la capa $i$ y la capa $i+1$. Si la capa $i$ tiene $n_i$ neuronas y la capa $i+1$ tiene $n_{i+1}$ neuronas, entonces las dimensiones de $W_{i}$ son $(n_{i+1}, n_i)$ y las de $b_i$ son $(n_{i+1}, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.331606Z",
     "start_time": "2020-10-19T12:30:27.324784Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- int: size of the input layer\n",
    "    n_h -- int: size of the hidden layer\n",
    "    n_y -- int: size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2) \n",
    "    \n",
    "    W1 = np.reshape(np.random.uniform(-0.1, 0.1, n_h*n_x), (n_h, n_x))  \n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.reshape(np.random.uniform(-0.1, 0.1, n_y*n_h), (n_y, n_h))    \n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.351024Z",
     "start_time": "2020-10-19T12:30:27.333217Z"
    }
   },
   "outputs": [],
   "source": [
    "initialize_parameters(n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:02:21.703636Z",
     "start_time": "2020-10-14T18:02:21.700427Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Conexión entre las neuronas de capas contiguas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "La función ```propagate()``` realiza la combinacion lineal entre los valores de salida de los nodos de una capa con los pesos y bias definidos entre esa capa y la siguiente. \n",
    "\n",
    "La función de activación que se aplica a esta combinación, es para considerar efectos no lineales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.396860Z",
     "start_time": "2020-10-19T12:30:27.382469Z"
    }
   },
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    \"\"\"\n",
    "    Compute the tanh of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- tanh(z)\n",
    "    \"\"\"\n",
    "    return np.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.411531Z",
     "start_time": "2020-10-19T12:30:27.398210Z"
    }
   },
   "outputs": [],
   "source": [
    "def tanh_derivative(z):\n",
    "    return 1-np.square(tanh(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.453828Z",
     "start_time": "2020-10-19T12:30:27.442238Z"
    }
   },
   "outputs": [],
   "source": [
    "def propagate(X, Y, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Zi es la combinacion lineal entre x y w\n",
    "    # Ai es la aplicacion de una funcion de activacion a Zi\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = Z2\n",
    "    \n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    m = Y.shape[1] # number of samples\n",
    "\n",
    "    cost = (1/m)*np.sum((Y-A2)**2)\n",
    "    cost = np.squeeze(cost)     \n",
    "    \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "        \n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "        \n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    \n",
    "    # Calculo de derivadas\n",
    "    \n",
    "    dZ2 = 2*(A2-Y)\n",
    "    dW2 = (1/m)*np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m)*np.sum(dZ2, axis = 1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T, dZ2)*tanh_derivative(A1)\n",
    "    dW1 = (1/m)*np.dot(dZ1, X.T)\n",
    "    db1 = (1/m)*np.sum(dZ1, axis = 1, keepdims = True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    \n",
    "    return A2, cache, cost, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.468709Z",
     "start_time": "2020-10-19T12:30:27.455330Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(X, Y, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    Y -- output data of size (n_y, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    cost -- the value of cost\n",
    "    grads -- a dictionary contains derivatives to update parameters\n",
    "    \"\"\"\n",
    "    # Regresa cada parametro del diccionario \"parameters\"\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Pasos 1 y 2:\n",
    "    \n",
    "    # Zi es la combinacion lineal entre x y w\n",
    "    # Ai es la aplicacion de una funcion de activacion a Zi:\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = Z2\n",
    "    \n",
    "    # se verifican las dimensiones de A2:\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "\n",
    "    # Paso 3:\n",
    "    \n",
    "    # numero de muestras:\n",
    "    \n",
    "    m = Y.shape[1] \n",
    "    \n",
    "    # se calcula el costo:\n",
    "\n",
    "    cost = (1/m)*np.sum((Y-A2)**2)\n",
    "    \n",
    "    # Asegura que cost sea un escalar:\n",
    "    \n",
    "    cost = np.squeeze(cost)      \n",
    "                                \n",
    "    assert(isinstance(cost, float))  \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Cálculo de la función de costo durante la optimización de los parámetros que definen al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Recordemos que la función de costo, $J$, nos permite saber qué tan bien se esta ajustando el modelo a la variable objetivo de las muestras. \n",
    "\n",
    "Para ello se buscan los parámetros que minimicen a esta función. \n",
    "\n",
    "En el presente caso, la función de costo está definida por la relación siguiente: \n",
    "\n",
    "$$J = \\dfrac{1}{m}\\sum_{i=0}^{m}(y_i-a_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.487768Z",
     "start_time": "2020-10-19T12:30:27.469959Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy cost given in equation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cross-entropy cost given equation (13)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # number of samples\n",
    "    cost = (1/m)*np.sum((Y-A2)**2) \n",
    "    cost = np.squeeze(cost)    \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Para encontrar a los valores optimos de los parametros, estos se acualizan en cada época empleando el algoritmo de gradiente descendente. El cual esta definido por la siguientes relaciones:\n",
    "\n",
    "$$ \\omega_k := \\omega_k - \\alpha \\dfrac{\\partial J(\\omega, b)}{\\partial \\omega_k}$$\n",
    "\n",
    "$$ b_l := b_l - \\alpha \\dfrac{\\partial J(\\omega, b)}{\\partial b_l}$$\n",
    "\n",
    "Es por ello necesario calcular las derivadas del costo respecto a cada uno de los parametros que definen al sistema de aprendizaje. $\\alpha$ es la relación de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.505202Z",
     "start_time": "2020-10-19T12:30:27.489153Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculation_of_derivatives(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation using the instructions above.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data of shape (2, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "        \n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    \n",
    "    # Calculo de derivadas\n",
    "    \n",
    "    dZ2 = 2*(A2-Y)\n",
    "    dW2 = (1/m)*np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m)*np.sum(dZ2, axis = 1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T, dZ2)*(1-np.power(A1, 2))\n",
    "    dW1 = (1/m)*np.dot(dZ1, X.T)\n",
    "    db1 = (1/m)*np.sum(dZ1, axis = 1, keepdims = True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Optimizacion de los pesos y los bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.522525Z",
     "start_time": "2020-10-19T12:30:27.506639Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(parameters, grads, learning_rate = 0.1):\n",
    "    \"\"\"\n",
    "    Updates parameters using the gradient descent update rule given above\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    W1 = W1-learning_rate*dW1\n",
    "    b1 = b1-learning_rate*db1\n",
    "    W2 = W2-learning_rate*dW2\n",
    "    b2 = b2-learning_rate*db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Las predicciones se realizan con los parametros óptimos encontrados en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.541290Z",
     "start_time": "2020-10-19T12:30:27.524245Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(parameters, X, Y):\n",
    "    \"\"\"\n",
    "    Using the learned parameters, predicts a class for each example in X\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data of size (n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model\n",
    "    \"\"\"\n",
    "    predictions =  []\n",
    "    A2, cache, cost, grads = propagate(X, Y, parameters)\n",
    "    predictions = tanh(A2) \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Las funciones anteriores se integran para generar, entrenar y validar la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.556923Z",
     "start_time": "2020-10-19T12:30:27.542893Z"
    }
   },
   "outputs": [],
   "source": [
    "def nn_model(X, Y, val_ratio, n_h, epochs, alpha, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- dataset of shape (2, number of examples)\n",
    "    Y -- labels of shape (1, number of examples)\n",
    "    n_h -- size of the hidden layer\n",
    "    num_iterations -- Number of iterations in gradient descent loop\n",
    "    print_cost -- if True, print the cost every 1000 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_ratio = int((1-val_ratio)*X.shape[1])\n",
    "    X_dev = X[:,train_ratio:]\n",
    "    Y_dev = Y[:,train_ratio:]\n",
    "\n",
    "    X = X[:,:train_ratio]\n",
    "    Y = Y[:,:train_ratio]\n",
    "    \n",
    "    print(\"Train\",X.shape,Y.shape)\n",
    "    print(\"val\",X_dev.shape,Y_dev.shape)\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    \n",
    "    n_x, n_h, n_y = layer_sizes(X, Y, n_h = n_h)\n",
    "        \n",
    "    # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"] \n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    \n",
    "    costs=[]\n",
    "    costs_dev = []\n",
    "    params = []\n",
    "    \n",
    "\n",
    "    for i in range(0, epochs):\n",
    "         \n",
    "        A2, cache, cost, grads = propagate(X, Y, parameters)\n",
    "        \n",
    "        cost_dev = validation(X_dev, Y_dev, parameters)\n",
    " \n",
    "        parameters = optimize(parameters, grads, alpha)\n",
    "        \n",
    "        params.append(parameters)\n",
    "        \n",
    "        costs.append(cost)\n",
    "        \n",
    "        costs_dev.append(cost_dev)\n",
    "                \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost and Cost_val in epoch %i: %f %f\" %(i, cost, cost_dev))\n",
    "            \n",
    "    return parameters, costs, params, costs_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:25:36.366411Z",
     "start_time": "2020-10-13T17:25:36.359140Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Entrenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='black'> \n",
    "Para monitorear el aprendizaje, las muestras para el aprendizaje se dividen en dos grupos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "El (1.0 - val_ratio) (90% en el presente caso) de ellas se emplean para realizar el aprendizaje y el (val_ratio) (el 10% en el presente caso) restante para evaluar, \"validar\", la calidad del aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:27.915899Z",
     "start_time": "2020-10-19T12:30:27.558441Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "learning_rate = 0.008\n",
    "val_ratio = 0.1\n",
    "n_h = 4\n",
    "\n",
    "opt_parameters, costs, params, costs_dev = nn_model(x_train, y_train, val_ratio=val_ratio, n_h = n_h, epochs = epochs, alpha=learning_rate, print_cost=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:28.050603Z",
     "start_time": "2020-10-19T12:30:27.918179Z"
    }
   },
   "outputs": [],
   "source": [
    "costs = np.squeeze(costs)\n",
    "plt.plot(costs, color='magenta')\n",
    "plt.plot(costs_dev, color='blue')\n",
    "\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['cost_train', 'cost_validation']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " ## Precision:\n",
    "\n",
    "Para calcular la precision del modelo se usa el error cuadrático medio, MSE:\n",
    "\n",
    "$$100-MSE*100$$\n",
    "\n",
    "es decir\n",
    "\n",
    "$$100-(\\dfrac{1}{m_{test}}\\sum_{i=1}^{m_{test}} (y_{i}-a_{i})^2)*100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:28.058593Z",
     "start_time": "2020-10-19T12:30:28.052555Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_train = predict(opt_parameters, x_train, y_train)\n",
    "\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.power(predictions_train-y_train, 2)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:28.072239Z",
     "start_time": "2020-10-19T12:30:28.060934Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_test = predict(opt_parameters, x_test, y_test)\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.power(predictions_test-y_test, 2)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "# Implementación de una red neuronal con Keras\n",
    "\n",
    "[Keras](https://keras.io/)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! conda install -c conda-forge keras=2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:29.198262Z",
     "start_time": "2020-10-19T12:30:28.074296Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:29.203899Z",
     "start_time": "2020-10-19T12:30:29.200024Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:29.215670Z",
     "start_time": "2020-10-19T12:30:29.205856Z"
    }
   },
   "outputs": [],
   "source": [
    "def architecture(input_shape, activation):\n",
    "    \n",
    "    model = Sequential()\n",
    "        \n",
    "    model.add(Dense(4, kernel_initializer='uniform', bias_initializer='zeros', \n",
    "                    activation=activation, \n",
    "                    input_shape=input_shape))    \n",
    "    model.add(Dense(1, kernel_initializer='uniform', bias_initializer='zeros', \n",
    "                    activation = activation))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:29.270312Z",
     "start_time": "2020-10-19T12:30:29.217078Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (10,)\n",
    "activation = 'tanh'\n",
    "\n",
    "model_keras = architecture(input_shape=input_shape, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:29.339922Z",
     "start_time": "2020-10-19T12:30:29.271780Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_keras, to_file='model.png', show_shapes=True, rankdir='TB', \n",
    "      expand_nested=True, show_layer_names=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:29.345560Z",
     "start_time": "2020-10-19T12:30:29.341445Z"
    }
   },
   "outputs": [],
   "source": [
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:29.458293Z",
     "start_time": "2020-10-19T12:30:29.346910Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "opt = Adam(learning_rate=lr)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "acc = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "model_keras.compile(loss=loss, \n",
    "              optimizer=opt,\n",
    "              metrics=[acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "start_time = time.time()\n",
    "val_split=0.1\n",
    "\n",
    "history_model = model_keras.fit(train_x, train_y,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=32,\n",
    "                          validation_split=val_split, \n",
    "                          shuffle=True,\n",
    "                          verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time for training: {:10.4f}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Gráfica del costo como función de la época    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:34.070694Z",
     "start_time": "2020-10-19T12:30:33.937072Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history_model.history['loss'], 'magenta')\n",
    "plt.plot(history_model.history['val_loss'], 'blue')\n",
    "plt.ylabel('Cost', size=16)\n",
    "plt.xlabel('Epoch', size=16)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5, color=blue>\n",
    "Evaluación del entrenamiento. Se realiza con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:34.080939Z",
     "start_time": "2020-10-19T12:30:34.072320Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = model_keras.evaluate(test_x, test_y)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5, color=blue>\n",
    "Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T12:30:34.113953Z",
     "start_time": "2020-10-19T12:30:34.082484Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model_keras.predict(test_x)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]*sigma + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
